{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 02. Feature & Target Dataset êµ¬ì¶•\n",
    "\n",
    "## ğŸ¯ ì´ ë‹¨ê³„ì˜ ë‹¨ í•˜ë‚˜ì˜ ëª©ì \n",
    "\n",
    "> **Raw ë°ì´í„°ë¥¼ \"ëª¨ë¸ê³¼ ìš´ì˜ì´ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì¼ ì •ì‹ ë°ì´í„°ì…‹\"ìœ¼ë¡œ ë³€í™˜**\n",
    "\n",
    "## ğŸ“‹ ì±…ì„ (Responsibility)\n",
    "\n",
    "### âœ… ì´ ë‹¨ê³„ê°€ í•˜ëŠ” ê²ƒ\n",
    "1. **Feature Builder**: ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (MA, RSI, MACD, Bollinger ë“±)\n",
    "2. **Universe Meta Builder**: ìš´ì˜ íŒë‹¨ìš© ë©”íƒ€ ì§€í‘œ (ìœ ë™ì„±, ë¦¬ìŠ¤í¬ ë“±)\n",
    "3. **History Filtering**: Feature ì¤€ë¹„ ê¸°ê°„(60ì¼) ì´í›„ ë°ì´í„°ë§Œ ìœ ì§€\n",
    "4. **ìŠ¤í‚¤ë§ˆ ê²€ì¦**: í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸\n",
    "5. **Parquet ì €ì¥**: ë‹¨ì¼ í†µí•© ë°ì´í„°ì…‹ ìƒì„±\n",
    "\n",
    "### âŒ ì´ ë‹¨ê³„ê°€ í•˜ì§€ ì•ŠëŠ” ê²ƒ\n",
    "- **Target ìƒì„±** (â†’ 03ë‹¨ê³„ì—ì„œ í•„ìš” ì‹œ ìƒì„±)\n",
    "- Train/Test Split (â†’ 03ë‹¨ê³„)\n",
    "- Normalization/Scaling (â†’ 03ë‹¨ê³„)\n",
    "- ìƒ˜í”Œ ì œê±°/í•„í„°ë§ (â†’ 03ë‹¨ê³„)\n",
    "\n",
    "## ğŸ”„ ë°ì´í„° íë¦„\n",
    "\n",
    "```\n",
    "data/01_raw/*.csv\n",
    "    â†“ [Load]\n",
    "  Raw DataFrame\n",
    "    â†“ [build_features]\n",
    "  + ê¸°ìˆ ì§€í‘œ\n",
    "    â†“ [build_universe_meta]\n",
    "  + ë©”íƒ€ ì§€í‘œ\n",
    "    â†“ [filter_by_history]\n",
    "  Feature ì¤€ë¹„ ê¸°ê°„(60ì¼) ì œê±°\n",
    "    â†“ [validate_schema]\n",
    "  ê²€ì¦ í†µê³¼\n",
    "    â†“ [save]\n",
    "data/03_processed/dataset.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Technical indicators module loaded\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ê¸°ìˆ ì  ì§€í‘œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.features.technical import (\n",
    "    calc_rsi,\n",
    "    calc_macd,\n",
    "    calc_bollinger,\n",
    "    calc_sma,\n",
    "    calc_volume_ratio\n",
    ")\n",
    "\n",
    "print(\"âœ… Technical indicators module loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ì…ë ¥: data\\01_raw\\krx_prices_20251226\n",
      "ğŸ“¤ ì¶œë ¥: data\\03_processed\\dataset_20251226.parquet\n",
      "â±ï¸  ìµœì†Œ íˆìŠ¤í† ë¦¬: 60ì¼ (Feature ì¤€ë¹„ ê¸°ê°„)\n"
     ]
    }
   ],
   "source": [
    "# ==================== ì„¤ì • ====================\n",
    "\n",
    "REFERENCE_DATE = \"20251226\"  # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€ì¼\n",
    "RAW_DATA_DIR = Path(f\"data/01_raw/krx_prices_{REFERENCE_DATE}\")\n",
    "OUTPUT_DIR = Path(\"data/03_processed\")\n",
    "OUTPUT_FILE = OUTPUT_DIR / f\"dataset_{REFERENCE_DATE}.parquet\"\n",
    "\n",
    "# Feature ì¤€ë¹„ ê¸°ê°„ (ìµœì¥ rolling window)\n",
    "MIN_HISTORY = 60  # MA_60ì´ ê°€ì¥ ê¸´ ê¸°ê°„\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“¥ ì…ë ¥: {RAW_DATA_DIR}\")\n",
    "print(f\"ğŸ“¤ ì¶œë ¥: {OUTPUT_FILE}\")\n",
    "print(f\"â±ï¸  ìµœì†Œ íˆìŠ¤í† ë¦¬: {MIN_HISTORY}ì¼ (Feature ì¤€ë¹„ ê¸°ê°„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functions",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Helper Functions\n",
    "\n",
    "### íŠ¸ë™ B ê°œë… ì ìš©: ì±…ì„ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technical_indicators",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Feature Builder: ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°\n",
    "# ==========================================\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ê¸°ìˆ ì  ì§€í‘œ Feature ìƒì„±\n",
    "    \n",
    "    ì±…ì„\n",
    "    ----\n",
    "    - ê°€ê²© ê¸°ë°˜ ê¸°ìˆ ì§€í‘œë§Œ ê³„ì‚°\n",
    "    - ê³¼ê±° ì •ë³´ë§Œ ì‚¬ìš© (ë¯¸ë˜ ì •ë³´ ì ˆëŒ€ ê¸ˆì§€)\n",
    "    - ì¢…ëª©ë³„(ticker) ê·¸ë£¹ ì—°ì‚°\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Raw ë°ì´í„° (ìµœì†Œ: date, ticker, close, volume)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        ì›ë³¸ + feature_* ì»¬ëŸ¼ ì¶”ê°€\n",
    "        \n",
    "    Note\n",
    "    ----\n",
    "    ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ì€ src.features.technical ëª¨ë“ˆ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ”¨ Building Features...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # ì¢…ëª©ë³„ ê·¸ë£¹ ì—°ì‚°\n",
    "    print(\"  - ì´ë™í‰ê·  (MA 5, 20, 60)...\")\n",
    "    for window in [5, 20, 60]:\n",
    "        df[f'feature_ma_{window}'] = df.groupby('ticker')['close'].transform(\n",
    "            lambda x: calc_sma(x, window)\n",
    "        )\n",
    "    \n",
    "    print(\"  - ë³€ë™ì„± (20ì¼ í‘œì¤€í¸ì°¨)...\")\n",
    "    df['feature_volatility_20'] = df.groupby('ticker')['close'].transform(\n",
    "        lambda x: x.pct_change().rolling(20).std()\n",
    "    )\n",
    "    \n",
    "    print(\"  - ê±°ë˜ëŸ‰ ë¹„ìœ¨...\")\n",
    "    df['feature_volume_ratio'] = df.groupby('ticker')['volume'].transform(\n",
    "        lambda x: calc_volume_ratio(x, 20)\n",
    "    )\n",
    "    \n",
    "    print(\"  - RSI (14ì¼)...\")\n",
    "    df['feature_rsi_14'] = df.groupby('ticker')['close'].transform(\n",
    "        lambda x: calc_rsi(x, 14)\n",
    "    )\n",
    "    \n",
    "    print(\"  - MACD...\")\n",
    "    # MACDëŠ” ê·¸ë£¹ë³„ë¡œ ê³„ì‚° í›„ í• ë‹¹\n",
    "    macd_results = []\n",
    "    for ticker, group in df.groupby('ticker'):\n",
    "        macd, macd_signal, macd_hist = calc_macd(group['close'])\n",
    "        temp = pd.DataFrame({\n",
    "            'ticker': ticker,\n",
    "            'date': group['date'].values,\n",
    "            'feature_macd': macd.values,\n",
    "            'feature_macd_signal': macd_signal.values,\n",
    "            'feature_macd_hist': macd_hist.values\n",
    "        })\n",
    "        macd_results.append(temp)\n",
    "    \n",
    "    macd_df = pd.concat(macd_results, ignore_index=True)\n",
    "    df = df.merge(macd_df, on=['ticker', 'date'], how='left')\n",
    "    \n",
    "    print(\"  - Bollinger Bands...\")\n",
    "    bollinger_results = []\n",
    "    for ticker, group in df.groupby('ticker'):\n",
    "        upper, middle, lower = calc_bollinger(group['close'])\n",
    "        temp = pd.DataFrame({\n",
    "            'ticker': ticker,\n",
    "            'date': group['date'].values,\n",
    "            'feature_bollinger_upper': upper.values,\n",
    "            'feature_bollinger_middle': middle.values,\n",
    "            'feature_bollinger_lower': lower.values\n",
    "        })\n",
    "        bollinger_results.append(temp)\n",
    "    \n",
    "    bollinger_df = pd.concat(bollinger_results, ignore_index=True)\n",
    "    df = df.merge(bollinger_df, on=['ticker', 'date'], how='left')\n",
    "    \n",
    "    feature_cols = [c for c in df.columns if c.startswith('feature_')]\n",
    "    print(f\"âœ… {len(feature_cols)}ê°œ Feature ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "target_builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Target Builder: ì˜ˆì¸¡ ëª©í‘œ ìƒì„±\n",
    "# ==========================================\n",
    "\n",
    "def build_targets(df: pd.DataFrame, horizon: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Target ë³€ìˆ˜ ìƒì„±\n",
    "    \n",
    "    ì±…ì„\n",
    "    ----\n",
    "    - nì¼ í›„ ìˆ˜ìµë¥  ê³„ì‚°\n",
    "    - ë¡œê·¸ ìˆ˜ìµë¥  ê³„ì‚°\n",
    "    - ë°©í–¥ì„± ë¼ë²¨ ìƒì„±\n",
    "    \n",
    "    ë¹„ì±…ì„\n",
    "    ------\n",
    "    - ì •ê·œí™”/ìŠ¤ì¼€ì¼ë§ (03ë‹¨ê³„)\n",
    "    - ìƒ˜í”Œ ì œê±° (03ë‹¨ê³„)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Featureê°€ ì¶”ê°€ëœ ë°ì´í„°\n",
    "    horizon : int\n",
    "        ì˜ˆì¸¡ ê¸°ê°„ (ì¼)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        ì›ë³¸ + target_* ì»¬ëŸ¼ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¯ Building Targets (Horizon: {horizon}ì¼)...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # ì¢…ëª©ë³„ ë¯¸ë˜ ê°€ê²© shift\n",
    "    print(\"  - Forward return ê³„ì‚°...\")\n",
    "    df['future_close'] = df.groupby('ticker')['close'].shift(-horizon)\n",
    "    \n",
    "    # ìˆ˜ìµë¥  ê³„ì‚°\n",
    "    df['target_return'] = (df['future_close'] / df['close']) - 1\n",
    "    df['target_log_return'] = np.log(df['future_close'] / df['close'])\n",
    "    \n",
    "    # ë°©í–¥ì„± ë¼ë²¨ (ìƒìŠ¹=1, í•˜ë½=0)\n",
    "    df['target_direction'] = (df['target_return'] > 0).astype(int)\n",
    "    \n",
    "    # ì„ì‹œ ì»¬ëŸ¼ ì œê±°\n",
    "    df = df.drop(columns=['future_close'])\n",
    "    \n",
    "    # NaN í†µê³„\n",
    "    target_cols = [c for c in df.columns if c.startswith('target_')]\n",
    "    nan_count = df[target_cols].isna().sum().sum()\n",
    "    total_count = len(df) * len(target_cols)\n",
    "    \n",
    "    print(f\"âœ… {len(target_cols)}ê°œ Target ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"   NaN: {nan_count}/{total_count} ({nan_count/total_count*100:.1f}%)\")\n",
    "    print(f\"   (ë§ˆì§€ë§‰ {horizon}ì¼ì¹˜ ë°ì´í„°ëŠ” Targetì´ ì—†ìŒ - ì •ìƒ)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "universe_meta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Universe Meta Builder: ìš´ì˜ íŒë‹¨ìš© ë©”íƒ€ ì§€í‘œ\n",
    "# ==========================================\n",
    "\n",
    "def build_universe_meta(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Universe ì„ ì •ìš© ë©”íƒ€ ì§€í‘œ ìƒì„±\n",
    "    \n",
    "    ì±…ì„\n",
    "    ----\n",
    "    03ë‹¨ê³„(ëª¨ë¸ í•™ìŠµ/ìš´ì˜)ì—ì„œ í•„ìš”í•œ íŒë‹¨ ì§€í‘œë¥¼ ì‚¬ì „ ê³„ì‚°\n",
    "    - ìœ ë™ì„± ì ìˆ˜\n",
    "    - ë¦¬ìŠ¤í¬ ë³µí•© ì ìˆ˜\n",
    "    - ê±°ë˜ ê°€ëŠ¥ ì—¬ë¶€ í”Œë˜ê·¸\n",
    "    \n",
    "    ëª©ì \n",
    "    ----\n",
    "    \"03ë‹¨ê³„ê°€ ë„ë©”ì¸ íŒë‹¨ì„ í•˜ì§€ ì•Šë„ë¡\" ë¯¸ë¦¬ ê³„ì‚°\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Feature + Targetì´ ì¶”ê°€ëœ ë°ì´í„°\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        ì›ë³¸ + ë©”íƒ€ ì§€í‘œ ì»¬ëŸ¼ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ›ï¸ Building Universe Meta...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. ìœ ë™ì„± ì ìˆ˜ (ê±°ë˜ëŒ€ê¸ˆ ê¸°ë°˜)\n",
    "    print(\"  - ìœ ë™ì„± ì ìˆ˜ ê³„ì‚°...\")\n",
    "    if 'amount' in df.columns:\n",
    "        # amountê°€ ìˆìœ¼ë©´ ì§ì ‘ ì‚¬ìš©\n",
    "        df['liquidity_score'] = df['amount']\n",
    "    else:\n",
    "        # ì—†ìœ¼ë©´ close * volumeìœ¼ë¡œ ì¶”ì •\n",
    "        df['liquidity_score'] = df['close'] * df['volume']\n",
    "    \n",
    "    # 20ì¼ í‰ê·  ìœ ë™ì„±\n",
    "    df['liquidity_score'] = df.groupby('ticker')['liquidity_score'].transform(\n",
    "        lambda x: x.rolling(20).mean()\n",
    "    )\n",
    "    \n",
    "    # 2. ë¦¬ìŠ¤í¬ ë³µí•© ì ìˆ˜ (ë‹¨ìˆœ ë²„ì „)\n",
    "    print(\"  - ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°...\")\n",
    "    # ë³€ë™ì„±ì´ ë†’ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ ì¦ê°€\n",
    "    df['risk_volatility'] = df['feature_volatility_20'].fillna(0)\n",
    "    \n",
    "    # ê±°ë˜ëŸ‰ ê¸‰ì¦ë„ ë¦¬ìŠ¤í¬ (í…Œë§ˆì£¼ ì˜ì‹¬)\n",
    "    df['risk_volume_surge'] = (df['feature_volume_ratio'] > 3.0).astype(int)\n",
    "    \n",
    "    # ë³µí•© ë¦¬ìŠ¤í¬ (0~1 ì •ê·œí™”)\n",
    "    df['risk_composite'] = (\n",
    "        df['risk_volatility'] / df['risk_volatility'].max() * 0.5 +\n",
    "        df['risk_volume_surge'] * 0.5\n",
    "    )\n",
    "    \n",
    "    # 3. ê±°ë˜ ê°€ëŠ¥ ì—¬ë¶€ í”Œë˜ê·¸ (Placeholder)\n",
    "    # ì‹¤ì œë¡œëŠ” ë³„ë„ API ì¡°íšŒ í•„ìš” (get_market_trading_halt ë“±)\n",
    "    # í˜„ì¬ëŠ” ìœ ë™ì„± ê·¹ë‹¨ì  ì €í•˜ë¥¼ ëŒ€ë¦¬ ì§€í‘œë¡œ ì‚¬ìš©\n",
    "    print(\"  - ê±°ë˜ ê°€ëŠ¥ ì—¬ë¶€ í”Œë˜ê·¸...\")\n",
    "    df['is_suspended'] = (df['volume'] == 0).astype(int)\n",
    "    df['is_delisted'] = 0  # Placeholder (ì‹¤ì œë¡œëŠ” ë³„ë„ ê´€ë¦¬ í•„ìš”)\n",
    "    \n",
    "    meta_cols = ['liquidity_score', 'risk_composite', 'is_suspended', 'is_delisted']\n",
    "    print(f\"âœ… {len(meta_cols)}ê°œ ë©”íƒ€ ì§€í‘œ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "schema_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Schema Validation: í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦\n",
    "# ==========================================\n",
    "\n",
    "def validate_schema(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    ìµœì¢… ë°ì´í„°ì…‹ ìŠ¤í‚¤ë§ˆ ê²€ì¦\n",
    "    \n",
    "    í•„ìˆ˜ ì»¬ëŸ¼ ê·¸ë£¹\n",
    "    ------------\n",
    "    1. ê¸°ë³¸: date, ticker\n",
    "    2. Feature: feature_*\n",
    "    3. Target: target_*\n",
    "    4. Meta: liquidity_score, risk_composite, is_suspended, is_delisted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        ê²€ì¦ í†µê³¼ ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    print(\"\\nâœ”ï¸  Schema Validation...\")\n",
    "    \n",
    "    # 1. ê¸°ë³¸ ì»¬ëŸ¼\n",
    "    required_base = ['date', 'ticker']\n",
    "    missing_base = [c for c in required_base if c not in df.columns]\n",
    "    \n",
    "    if missing_base:\n",
    "        print(f\"âŒ í•„ìˆ˜ ê¸°ë³¸ ì»¬ëŸ¼ ëˆ„ë½: {missing_base}\")\n",
    "        return False\n",
    "    print(f\"   âœ… ê¸°ë³¸ ì»¬ëŸ¼: {required_base}\")\n",
    "    \n",
    "    # 2. Feature ì»¬ëŸ¼\n",
    "    feature_cols = [c for c in df.columns if c.startswith('feature_')]\n",
    "    if len(feature_cols) == 0:\n",
    "        print(\"âŒ Feature ì»¬ëŸ¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        return False\n",
    "    print(f\"   âœ… Feature: {len(feature_cols)}ê°œ\")\n",
    "    \n",
    "    # 3. Meta ì»¬ëŸ¼ (Targetì€ 03ë‹¨ê³„ì—ì„œ ìƒì„±í•˜ë¯€ë¡œ ì œì™¸)\n",
    "    required_meta = ['liquidity_score', 'risk_composite', 'is_suspended', 'is_delisted']\n",
    "    missing_meta = [c for c in required_meta if c not in df.columns]\n",
    "    \n",
    "    if missing_meta:\n",
    "        print(f\"âš ï¸  ê¶Œì¥ ë©”íƒ€ ì»¬ëŸ¼ ëˆ„ë½: {missing_meta}\")\n",
    "        print(\"   (ê²½ê³ ë§Œ í‘œì‹œ, ì €ì¥ì€ ì§„í–‰)\")\n",
    "    else:\n",
    "        print(f\"   âœ… ë©”íƒ€: {required_meta}\")\n",
    "    \n",
    "    # 4. ë°ì´í„° í†µê³„\n",
    "    print(f\"\\nğŸ“Š ìµœì¢… ë°ì´í„° í†µê³„:\")\n",
    "    print(f\"   - í–‰ ìˆ˜: {len(df):,}\")\n",
    "    print(f\"   - ì¢…ëª© ìˆ˜: {df['ticker'].nunique():,}\")\n",
    "    print(f\"   - ê¸°ê°„: {df['date'].min()} ~ {df['date'].max()}\")\n",
    "    print(f\"   - ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}\")\n",
    "    \n",
    "    # 5. NaN ì²´í¬ (Featureì— NaNì´ ìˆìœ¼ë©´ ê²½ê³ )\n",
    "    feature_nan = df[feature_cols].isna().sum().sum()\n",
    "    if feature_nan > 0:\n",
    "        print(f\"\\nâš ï¸  Feature NaN ë°œê²¬: {feature_nan}ê°œ\")\n",
    "        print(\"   â†’ ê±°ë˜ì •ì§€ ë“± ì˜ë¯¸ ìˆëŠ” NaNì¼ ìˆ˜ ìˆìŒ (ì •ìƒ)\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main_pipeline",
   "metadata": {},
   "source": [
    "## ğŸš€ Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading Raw CSV Files...\n",
      "   ë°œê²¬ëœ íŒŒì¼: 2905ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading CSVs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2905/2905 [00:07<00:00, 390.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Raw ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n",
      "   - ì´ í–‰ ìˆ˜: 681,346\n",
      "   - ì¢…ëª© ìˆ˜: 2,905\n",
      "   - ê¸°ê°„: 2025-01-02 00:00:00 ~ 2025-12-26 00:00:00\n",
      "\n",
      "   ì»¬ëŸ¼: ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume', 'change_pct']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Load Raw Data\n",
    "# ==========================================\n",
    "\n",
    "print(\"ğŸ“¥ Loading Raw CSV Files...\")\n",
    "\n",
    "csv_files = list(RAW_DATA_DIR.glob(\"*.csv\"))\n",
    "print(f\"   ë°œê²¬ëœ íŒŒì¼: {len(csv_files)}ê°œ\")\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"Raw ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {RAW_DATA_DIR}\")\n",
    "\n",
    "# ëª¨ë“  CSV ë¡œë“œ\n",
    "all_data = []\n",
    "for csv_file in tqdm(csv_files, desc=\"Loading CSVs\"):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(csv_file)\n",
    "        df_temp['date'] = pd.to_datetime(df_temp['date'])\n",
    "        all_data.append(df_temp)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  {csv_file.name} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# í†µí•©\n",
    "df_raw = pd.concat(all_data, ignore_index=True)\n",
    "df_raw = df_raw.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ… Raw ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - ì´ í–‰ ìˆ˜: {len(df_raw):,}\")\n",
    "print(f\"   - ì¢…ëª© ìˆ˜: {df_raw['ticker'].nunique():,}\")\n",
    "print(f\"   - ê¸°ê°„: {df_raw['date'].min()} ~ {df_raw['date'].max()}\")\n",
    "print(f\"\\n   ì»¬ëŸ¼: {list(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "build_features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¨ Building Features...\n",
      "  - ì´ë™í‰ê·  (MA 5, 20, 60)...\n",
      "  - ë³€ë™ì„± (20ì¼ í‘œì¤€í¸ì°¨)...\n",
      "  - ê±°ë˜ëŸ‰ ë¹„ìœ¨...\n",
      "  - RSI (14ì¼)...\n",
      "  - MACD...\n",
      "  - Bollinger Bands...\n",
      "âœ… 12ê°œ Feature ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. Build Features\n",
    "# ==========================================\n",
    "\n",
    "df_features = build_features(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "build_targets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. History Filtering\n",
    "# ==========================================\n",
    "\n",
    "# ì¢…ëª©ë³„ë¡œ 60ì¼ ì´í›„ ë°ì´í„°ë§Œ ìœ ì§€\n",
    "def filter_by_history(group, min_history=60):\n",
    "    return group.iloc[MIN_HISTORY:] if len(group) > MIN_HISTORY else pd.DataFrame()\n",
    "\n",
    "df_filtered = filter_by_history(df_features, min_history=MIN_HISTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "build_meta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›ï¸ Building Universe Meta...\n",
      "  - ìœ ë™ì„± ì ìˆ˜ ê³„ì‚°...\n",
      "  - ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°...\n",
      "  - ê±°ë˜ ê°€ëŠ¥ ì—¬ë¶€ í”Œë˜ê·¸...\n",
      "âœ… 4ê°œ ë©”íƒ€ ì§€í‘œ ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. Build Universe Meta\n",
    "# ==========================================\n",
    "\n",
    "df_final = build_universe_meta(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "validate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ”ï¸  Schema Validation...\n",
      "   âœ… ê¸°ë³¸ ì»¬ëŸ¼: ['date', 'ticker']\n",
      "   âœ… Feature: 12ê°œ\n",
      "   âœ… ë©”íƒ€: ['liquidity_score', 'risk_composite', 'is_suspended', 'is_delisted']\n",
      "\n",
      "ğŸ“Š ìµœì¢… ë°ì´í„° í†µê³„:\n",
      "   - í–‰ ìˆ˜: 681,286\n",
      "   - ì¢…ëª© ìˆ˜: 2,905\n",
      "   - ê¸°ê°„: 2025-01-02 00:00:00 ~ 2025-12-26 00:00:00\n",
      "   - ì „ì²´ ì»¬ëŸ¼ ìˆ˜: 26\n",
      "\n",
      "âš ï¸  Feature NaN ë°œê²¬: 551509ê°œ\n",
      "   â†’ ê±°ë˜ì •ì§€ ë“± ì˜ë¯¸ ìˆëŠ” NaNì¼ ìˆ˜ ìˆìŒ (ì •ìƒ)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. Validate Schema\n",
    "# ==========================================\n",
    "\n",
    "if not validate_schema(df_final):\n",
    "    raise ValueError(\"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨! ìœ„ì˜ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Saving to Parquet...\n",
      "   ê²½ë¡œ: data\\03_processed\\dataset_20251226.parquet\n",
      "âœ… ì €ì¥ ì™„ë£Œ!\n",
      "   - íŒŒì¼ í¬ê¸°: 72.41 MB\n",
      "   - í–‰ ìˆ˜: 681,286\n",
      "   - ì»¬ëŸ¼ ìˆ˜: 26\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. Save to Parquet\n",
    "# ==========================================\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saving to Parquet...\")\n",
    "print(f\"   ê²½ë¡œ: {OUTPUT_FILE}\")\n",
    "\n",
    "# tickerë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜ (Parquet íƒ€ì… ì¶”ë¡  ì˜¤ë¥˜ ë°©ì§€)\n",
    "df_final['ticker'] = df_final['ticker'].astype(str)\n",
    "\n",
    "df_final.to_parquet(\n",
    "    OUTPUT_FILE,\n",
    "    compression='snappy',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ì €ì¥ í™•ì¸\n",
    "file_size_mb = OUTPUT_FILE.stat().st_size / (1024 * 1024)\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"   - íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB\")\n",
    "print(f\"   - í–‰ ìˆ˜: {len(df_final):,}\")\n",
    "print(f\"   - ì»¬ëŸ¼ ìˆ˜: {len(df_final.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify",
   "metadata": {},
   "source": [
    "## âœ… ê²°ê³¼ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "verify_output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì €ì¥ëœ ë°ì´í„° ê²€ì¦:\n",
      "\n",
      "ğŸ“‹ ì»¬ëŸ¼ ê·¸ë£¹ë³„ ê°œìˆ˜:\n",
      "   - ê¸°ë³¸: 14\n",
      "   - Feature: 12\n",
      "\n",
      "ğŸ“Š ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change_pct</th>\n",
       "      <th>feature_ma_5</th>\n",
       "      <th>feature_ma_20</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_macd_hist</th>\n",
       "      <th>feature_bollinger_upper</th>\n",
       "      <th>feature_bollinger_middle</th>\n",
       "      <th>feature_bollinger_lower</th>\n",
       "      <th>liquidity_score</th>\n",
       "      <th>risk_volatility</th>\n",
       "      <th>risk_volume_surge</th>\n",
       "      <th>risk_composite</th>\n",
       "      <th>is_suspended</th>\n",
       "      <th>is_delisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>20</td>\n",
       "      <td>5980</td>\n",
       "      <td>6080</td>\n",
       "      <td>5910</td>\n",
       "      <td>6010</td>\n",
       "      <td>27400</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>6137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.823171</td>\n",
       "      <td>6303.461628</td>\n",
       "      <td>6137.0</td>\n",
       "      <td>5970.538372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>20</td>\n",
       "      <td>6050</td>\n",
       "      <td>6100</td>\n",
       "      <td>5910</td>\n",
       "      <td>6010</td>\n",
       "      <td>66624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>6123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.976443</td>\n",
       "      <td>6282.221792</td>\n",
       "      <td>6123.0</td>\n",
       "      <td>5963.778208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>20</td>\n",
       "      <td>5990</td>\n",
       "      <td>5990</td>\n",
       "      <td>5740</td>\n",
       "      <td>5750</td>\n",
       "      <td>73155</td>\n",
       "      <td>-4.326123</td>\n",
       "      <td>5962.0</td>\n",
       "      <td>6098.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.312267</td>\n",
       "      <td>6320.384275</td>\n",
       "      <td>6098.5</td>\n",
       "      <td>5876.615725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker  open  high   low  close  volume  change_pct  \\\n",
       "0 2025-04-03     20  5980  6080  5910   6010   27400    0.166667   \n",
       "1 2025-04-04     20  6050  6100  5910   6010   66624    0.000000   \n",
       "2 2025-04-07     20  5990  5990  5740   5750   73155   -4.326123   \n",
       "\n",
       "   feature_ma_5  feature_ma_20  ...  feature_macd_hist  \\\n",
       "0        6020.0         6137.0  ...         -15.823171   \n",
       "1        6010.0         6123.0  ...         -13.976443   \n",
       "2        5962.0         6098.5  ...         -28.312267   \n",
       "\n",
       "   feature_bollinger_upper  feature_bollinger_middle  feature_bollinger_lower  \\\n",
       "0              6303.461628                    6137.0              5970.538372   \n",
       "1              6282.221792                    6123.0              5963.778208   \n",
       "2              6320.384275                    6098.5              5876.615725   \n",
       "\n",
       "   liquidity_score  risk_volatility  risk_volume_surge  risk_composite  \\\n",
       "0              NaN         0.006555                  0        0.000352   \n",
       "1              NaN         0.006574                  0        0.000353   \n",
       "2              NaN         0.011258                  0        0.000605   \n",
       "\n",
       "   is_suspended  is_delisted  \n",
       "0             0            0  \n",
       "1             0            0  \n",
       "2             0            0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¢ Feature NaN ì²´í¬:\n",
      "   NaNì´ ìˆëŠ” Feature:\n",
      "feature_ma_5                 11613\n",
      "feature_ma_20                54950\n",
      "feature_ma_60               169667\n",
      "feature_volatility_20        57832\n",
      "feature_volume_ratio         54950\n",
      "feature_rsi_14               37647\n",
      "feature_bollinger_upper      54950\n",
      "feature_bollinger_middle     54950\n",
      "feature_bollinger_lower      54950\n",
      "dtype: int64\n",
      "   â†’ ê±°ë˜ì •ì§€ ë“± ì˜ë¯¸ ìˆëŠ” NaNì¼ ìˆ˜ ìˆìŒ\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ íŒŒì¼ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ê²€ì¦\n",
    "df_verify = pd.read_parquet(OUTPUT_FILE)\n",
    "\n",
    "print(\"ğŸ” ì €ì¥ëœ ë°ì´í„° ê²€ì¦:\")\n",
    "print(f\"\\nğŸ“‹ ì»¬ëŸ¼ ê·¸ë£¹ë³„ ê°œìˆ˜:\")\n",
    "print(f\"   - ê¸°ë³¸: {len([c for c in df_verify.columns if not c.startswith('feature_')])}\")\n",
    "print(f\"   - Feature: {len([c for c in df_verify.columns if c.startswith('feature_')])}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):\")\n",
    "display(df_verify.head(3))\n",
    "\n",
    "print(f\"\\nğŸ”¢ Feature NaN ì²´í¬:\")\n",
    "feature_cols = [c for c in df_verify.columns if c.startswith('feature_')]\n",
    "nan_count = df_verify[feature_cols].isna().sum()\n",
    "if nan_count.sum() > 0:\n",
    "    print(\"   NaNì´ ìˆëŠ” Feature:\")\n",
    "    print(nan_count[nan_count > 0])\n",
    "    print(\"   â†’ ê±°ë˜ì •ì§€ ë“± ì˜ë¯¸ ìˆëŠ” NaNì¼ ìˆ˜ ìˆìŒ\")\n",
    "else:\n",
    "    print(\"   âœ… ëª¨ë“  Featureê°€ ì™„ì „í•¨ (NaN ì—†ìŒ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_step",
   "metadata": {},
   "source": [
    "## âœ… ì™„ë£Œ!\n",
    "\n",
    "### ìƒì„±ëœ íŒŒì¼\n",
    "- `data/03_processed/dataset.parquet`\n",
    "\n",
    "### ì´ ë°ì´í„°ì…‹ì˜ íŠ¹ì§•\n",
    "1. **Feature ì¤€ë¹„ ê¸°ê°„ ì œê±°**: ê° ì¢…ëª©ì˜ ì²˜ìŒ 60ì¼ì€ ì œì™¸ë¨\n",
    "2. **ì™„ì „í•œ Feature**: ëª¨ë“  í–‰ì´ ê³„ì‚° ê°€ëŠ¥í•œ Featureë¥¼ ê°€ì§\n",
    "3. **ì˜ë¯¸ ìˆëŠ” NaN ë³´ì¡´**: ê±°ë˜ì •ì§€ ë“±ìœ¼ë¡œ ì¸í•œ NaNì€ ìœ ì§€ë¨\n",
    "4. **Target ì—†ìŒ**: 03ë‹¨ê³„ì—ì„œ í•„ìš” ì‹œ ìƒì„±\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "```bash\n",
    "python scripts/03_train_predict.py\n",
    "```\n",
    "\n",
    "### 03ë‹¨ê³„ì—ì„œ í•  ì¼\n",
    "1. **Target ìƒì„±**: ì˜ˆì¸¡ ëª©í‘œ ì •ì˜ í›„ ìƒì„±\n",
    "2. **Train/Test Split**: Walk-Forward ì‹œê³„ì—´ ë¶„í• \n",
    "3. **Feature Scaling**: RobustScaler ì ìš©\n",
    "4. **ëª¨ë¸ í•™ìŠµ**: LightGBM í›ˆë ¨\n",
    "5. **Universe ì„ ì •**: Meta ì§€í‘œ í™œìš©\n",
    "\n",
    "### ë°ì´í„° ì‚¬ìš© ì˜ˆì‹œ\n",
    "```python\n",
    "df = pd.read_parquet('data/03_processed/dataset.parquet')\n",
    "\n",
    "# Target ìƒì„± (03ë‹¨ê³„)\n",
    "df['target'] = df.groupby('ticker')['close'].shift(-5) / df['close'] - 1\n",
    "\n",
    "# Feature ì¶”ì¶œ\n",
    "features = [c for c in df.columns if c.startswith('feature_')]\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
